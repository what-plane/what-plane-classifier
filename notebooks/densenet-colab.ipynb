{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import random\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Get COLAB runtime\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    DEVICE = 'TPU'\n",
    "elif os.environ['COLAB_GPU']=='1':\n",
    "    DEVICE = 'GPU'\n",
    "else:\n",
    "    DEVICE = 'CPU'\n",
    "print('Using', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If TPU, import xla\n",
    "if DEVICE=='TPU':\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default device\n",
    "if DEVICE=='TPU':\n",
    "    device = xm.xla_device()\n",
    "elif DEVICE=='GPU':\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BANNERHEIGHT = 12\n",
    "ROTATION_ANGLE = 10\n",
    "\n",
    "NORM = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw/airlinersnet/'\n",
    "batch_size = 16\n",
    "\n",
    "feature_extract=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    # Data loading and normalization for training\n",
    "\n",
    "    rad = math.radians(ROTATION_ANGLE)\n",
    "    c = math.cos(rad)\n",
    "    s = math.sin(rad)\n",
    "    \n",
    "    l = IMAGE_SIZE/2\n",
    "\n",
    "    x = l*c-l*s\n",
    "    y = l*s+l*c\n",
    "    rotpad = math.ceil(max(x,y)-l)\n",
    "\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Pad((0,0,0,-BANNERHEIGHT)), # Crop banner from bottom edge of image\n",
    "                transforms.Resize(240),\n",
    "                transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Pad(rotpad, padding_mode='reflect'), # Mirror boundary to avoid empty corners of rotated image\n",
    "                transforms.RandomRotation(ROTATION_ANGLE),\n",
    "                transforms.CenterCrop(IMAGE_SIZE),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(*NORM)\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Pad((0,0,0,-BANNERHEIGHT)),\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(IMAGE_SIZE),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(*NORM)\n",
    "            ]\n",
    "        ),\n",
    "        \"test\": transforms.Compose(\n",
    "            [\n",
    "                transforms.Pad((0,0,0,-BANNERHEIGHT)),\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(IMAGE_SIZE),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(*NORM)\n",
    "            ]\n",
    "        ),\n",
    "      }\n",
    "\n",
    "    # Load the datasets with ImageFolder\n",
    "    image_datasets = {x:datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
    "\n",
    "    # Dataloaders\n",
    "    dataloaders = {x:torch.utils.data.DataLoader(image_datasets[x], batch_size = batch_size, shuffle=True, num_workers=4) for x in ['train', 'valid', 'test']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
    "    return image_datasets, dataloaders, dataset_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(NORM[0])\n",
    "    std = np.array(NORM[1])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-94c459368d24>, line 18)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-94c459368d24>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    model_transfer = model_transfer.to(device)\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def init_model():\n",
    "\tmodel_transfer = models.densenet161(pretrained=True)\n",
    "\n",
    "\t# Freeze training for all \"features\" layers\n",
    "\tfor param in model_transfer.features.parameters():\n",
    "\t\tparam.requires_grad = False\n",
    "\t\t\n",
    "\tnum_classes = len(image_datasets['train'].class_to_idx)\n",
    "\tinput_size = model_transfer.classifier.state_dict()[next(iter(model_transfer.classifier.state_dict()))].size(1)\n",
    "\thidden_units = int(input_sze/2)\n",
    "\n",
    "\tmodel_transfer.classifier = nn.Sequential(OrderedDict([\n",
    "\t\t\t\t\t\t\t\t('fc1', nn.Linear(input_size, hidden_units)),\n",
    "\t\t\t\t\t\t\t\t('relu', nn.ReLU()),\n",
    "\t\t\t\t\t\t\t\t('drop', nn.Dropout(0.4)),\n",
    "\t\t\t\t\t\t\t\t('fc2', nn.Linear(hidden_units, num_classes))\n",
    "\n",
    "\tmodel_transfer = model_transfer.to(device)\n",
    "\n",
    "\treturn model_transfer\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select correct optimizer step function for runtime\n",
    "def step(optimizer):\n",
    "    if DEVICE=='TPU':\n",
    "        xm.optimizer_step(optimizer, barrier=True) \n",
    "    else:\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, save_path):\n",
    "    # Tensorboard writer\n",
    "    writer = SummaryWriter()\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    writer.flush()\n",
    "    \n",
    "    print('Training for {} epochs on {}\\n'.format(n_epochs, DEVICE))\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    losses = {'train':[], 'validation':[]}\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "\t\tfor batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\t\t\t# move to default device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\t\t\tstep(optimizer)\n",
    "            train_loss += ((1/(batch_idx+1))*(loss.data-train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "\t\t\t\t# move to default device\n",
    "\t\t\t\tdata, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += ((1/(batch_idx+1))*(loss.data-valid_loss))\n",
    "                ## update the average validation loss\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        losses['train'].append(train_loss)\n",
    "        losses['validation'].append(valid_loss)\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Valid\", valid_loss, epoch)\n",
    "\n",
    "\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss<valid_loss_min:\n",
    "            print('Saving model', save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "    # plotting losses\n",
    "    plt.plot(losses['train'], label='Training Loss')\n",
    "    plt.plot(losses['validation'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    _ = plt.ylim()\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "\t\t# move to default device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*NORM)\n",
    "    ])\n",
    "\n",
    "def predict(img_path, model):\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    inputs = transform(img).unsqueeze(dim=0)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # move to default device\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    model.train()\n",
    "\n",
    "    return preds.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets, dataloaders, dataset_sizes = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../src/data/airlinersnet_mapping.json\",\"r\") as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "class_names = [cat_to_name[x] for x in image_datasets['train'].classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.001, momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = train(30, dataloaders, model_transfer, optimizer_transfer, criterion_transfer, 'model_densenet_sgd_30_airlinersnet.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_transfer, 'densenet_full_-30-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.load_state_dict(torch.load('model_densenet_sgd_30_airlinersnet.pt'))\n",
    "model_transfer = torch.load('densenet_full_-30-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(dataloaders, model_transfer, criterion_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aircraft(img_path):\n",
    "    idx = predict(img_path, model_transfer)\n",
    "    return class_names[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def caption_images(img_path):\n",
    "    print(f\"This looks like a: {predict_aircraft(img_path)}\")\n",
    "    plot_image(img_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_test_img_dir = glob(\"../data/processed/test_images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../src/data/airlinersnet_mapping.json\",\"r\") as f:\n",
    "    cat_to_name = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_mapping = image_datasets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('torch_mapping.json','w') as f:\n",
    "    json.dump(torch_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in random.sample(list(extra_test_img_dir),3):\n",
    "    print(predict_aircraft(i))\n",
    "    plot_image(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}