{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tqdm import tqdm\r\n",
    "from PIL import Image\r\n",
    "from collections import OrderedDict\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.models as models\r\n",
    "from torch.optim import lr_scheduler\r\n",
    "from torchvision import datasets\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "\r\n",
    "use_cuda = torch.cuda.is_available()\r\n",
    "\r\n",
    "\r\n",
    "from PIL import ImageFile\r\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
    "\r\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw/airlinersnet/'\r\n",
    "batch_size = 10\r\n",
    "feature_extract=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and normalization for training\r\n",
    "norm = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
    "\r\n",
    "data_transforms = {\r\n",
    "    'train':transforms.Compose([\r\n",
    "        transforms.Resize(255),\r\n",
    "        transforms.RandomRotation(30),\r\n",
    "        transforms.RandomResizedCrop(224),\r\n",
    "        transforms.RandomHorizontalFlip(),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize(*norm)\r\n",
    "    ]),\r\n",
    "    'valid':transforms.Compose([\r\n",
    "        transforms.Resize(255),\r\n",
    "        transforms.CenterCrop(224),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize(*norm)\r\n",
    "    ]),\r\n",
    "     'test':transforms.Compose([\r\n",
    "        transforms.Resize(255),\r\n",
    "        transforms.CenterCrop(224),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize(*norm)\r\n",
    "    ]),\r\n",
    "}\r\n",
    "\r\n",
    "# Load the datasets with ImageFolder\r\n",
    "image_datasets = {x:datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid', 'test']}\r\n",
    "\r\n",
    "# Dataloaders\r\n",
    "dataloaders = {x:torch.utils.data.DataLoader(image_datasets[x], batch_size = batch_size, shuffle=True) for x in ['train', 'valid', 'test']}\r\n",
    "\r\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\r\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\r\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\r\n",
    "    mean = np.array([0.485, 0.456, 0.406])\r\n",
    "    std = np.array([0.229, 0.224, 0.225])\r\n",
    "    inp = std * inp + mean\r\n",
    "    inp = np.clip(inp, 0, 1)\r\n",
    "    plt.imshow(inp)\r\n",
    "    if title is not None:\r\n",
    "        plt.title(title)\r\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\r\n",
    "\r\n",
    "\r\n",
    "# Get a batch of training data\r\n",
    "inputs, classes = next(iter(dataloaders['train']))\r\n",
    "\r\n",
    "# Make a grid from batch\r\n",
    "out = torchvision.utils.make_grid(inputs)\r\n",
    "\r\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "model_transfer = models.densenet161(pretrained=True)\r\n",
    "\r\n",
    "num_classes = len(image_datasets['train'])\r\n",
    "num_features = model_transfer.classifier.in_features\r\n",
    "input_size = model_transfer.classifier.state_dict()[next(iter(model_transfer.classifier.state_dict()))].size(1)\r\n",
    "hidden_units = int(input_size/2)\r\n",
    "\r\n",
    "\r\n",
    "model_transfer.classifier = nn.Sequential(OrderedDict([\r\n",
    "                            ('fc1', nn.Linear(input_size, hidden_units)),\r\n",
    "                            ('relu', nn.ReLU()),\r\n",
    "                            ('drop', nn.Dropout(0.4)),\r\n",
    "                            ('fc2', nn.Linear(hidden_units, num_classes))\r\n",
    "]))\r\n",
    "    \r\n",
    "\r\n",
    "if use_cuda:\r\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\r\n",
    "    # Tensorboard writer\r\n",
    "    writer = SummaryWriter()\r\n",
    "    \"\"\"returns trained model\"\"\"\r\n",
    "    \r\n",
    "    print('Training for {} epochs on {}\\n'.format(n_epochs, 'GPU' if use_cuda else 'CPU'))\r\n",
    "    # initialize tracker for minimum validation loss\r\n",
    "    valid_loss_min = np.Inf \r\n",
    "    \r\n",
    "    losses = {'train':[], 'validation':[]}\r\n",
    "    for epoch in range(1, n_epochs+1):\r\n",
    "        # initialize variables to monitor training and validation loss\r\n",
    "        train_loss = 0.0\r\n",
    "        valid_loss = 0.0\r\n",
    "        \r\n",
    "        ###################\r\n",
    "        # train the model #\r\n",
    "        ###################\r\n",
    "        model.train()\r\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\r\n",
    "            # move to GPU\r\n",
    "            if use_cuda:\r\n",
    "                data, target = data.cuda(), target.cuda()\r\n",
    "            ## find the loss and update the model parameters accordingly\r\n",
    "            ## record the average training loss, using something like\r\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\r\n",
    "            optimizer.zero_grad()\r\n",
    "            output = model(data)\r\n",
    "            loss = criterion(output, target)\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            train_loss += ((1/(batch_idx+1))*(loss.data-train_loss))\r\n",
    "            \r\n",
    "        ######################    \r\n",
    "        # validate the model #\r\n",
    "        ######################\r\n",
    "        model.eval()\r\n",
    "        with torch.no_grad():\r\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\r\n",
    "                # move to GPU\r\n",
    "                if use_cuda:\r\n",
    "                    data, target = data.cuda(), target.cuda()\r\n",
    "                output = model(data)\r\n",
    "                loss = criterion(output, target)\r\n",
    "                valid_loss += ((1/(batch_idx+1))*(loss.data-valid_loss))\r\n",
    "                ## update the average validation loss\r\n",
    "\r\n",
    "            \r\n",
    "        # print training/validation statistics \r\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\r\n",
    "            epoch, \r\n",
    "            train_loss,\r\n",
    "            valid_loss\r\n",
    "            ))\r\n",
    "        losses['train'].append(train_loss)\r\n",
    "        losses['validation'].append(valid_loss)\r\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\r\n",
    "        writer.add_scalar(\"Loss/Valid\", valid_loss, epoch)\r\n",
    "\r\n",
    "\r\n",
    "        ## TODO: save the model if validation loss has decreased\r\n",
    "        if valid_loss<valid_loss_min:\r\n",
    "            print('Saving model', save_path)\r\n",
    "            valid_loss_min = valid_loss\r\n",
    "            torch.save(model.state_dict(), save_path)\r\n",
    "            \r\n",
    "    # plotting losses\r\n",
    "    plt.plot(losses['train'], label='Training Loss')\r\n",
    "    plt.plot(losses['validation'], label='Validation Loss')\r\n",
    "    plt.legend()\r\n",
    "    _ = plt.ylim()\r\n",
    "    \r\n",
    "    # return trained model\r\n",
    "    return model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\r\n",
    "\r\n",
    "    # monitor test loss and accuracy\r\n",
    "    test_loss = 0.\r\n",
    "    correct = 0.\r\n",
    "    total = 0.\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\r\n",
    "        # move to GPU\r\n",
    "        if use_cuda:\r\n",
    "            data, target = data.cuda(), target.cuda()\r\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\r\n",
    "        output = model(data)\r\n",
    "        # calculate the loss\r\n",
    "        loss = criterion(output, target)\r\n",
    "        # update average test loss \r\n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\r\n",
    "        # convert output probabilities to predicted class\r\n",
    "        pred = output.data.max(1, keepdim=True)[1]\r\n",
    "        # compare predictions to true label\r\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\r\n",
    "        total += data.size(0)\r\n",
    "            \r\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\r\n",
    "\r\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\r\n",
    "        100. * correct / total, correct, total))\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path, model):\r\n",
    "\r\n",
    "    img = Image.open(img_path)\r\n",
    "\r\n",
    "    inputs = transform(img).unsqueeze(dim=0)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        if use_cuda:\r\n",
    "            inputs = inputs.cuda()\r\n",
    "        outputs = model(inputs)\r\n",
    "        _, preds = torch.max(outputs, 1)\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    \r\n",
    "    return preds.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\r\n",
    "optimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = train(50, dataloaders, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_densenet_sgd_50_airlinersnet.pt')\r\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.load_state_dict(torch.load('model_densenet_sgd_50_airlinersnet.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(dataloaders, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\r\n",
    "with open(\"../src/data/airlinersnet_mapping.json\",\"r\") as f:\r\n",
    "    cat_to_name = json.load(f)\r\n",
    "\r\n",
    "class_names = [cat_to_name[x] for x in image_datasets['train'].classes]\r\n",
    "\r\n",
    "transform = transforms.Compose([transforms.Resize(224),\r\n",
    "                                transforms.CenterCrop(224),\r\n",
    "                                transforms.ToTensor(),\r\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],\r\n",
    "                                                        [0.229, 0.224, 0.225])])\r\n",
    "                                                        \r\n",
    "def predict_aircraft(img_path):\r\n",
    "    idx = predict(img_path, model_transfer)\r\n",
    "    return class_names[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_path):\r\n",
    "    img = cv2.imread(img_path)\r\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "    plt.imshow(rgb)\r\n",
    "    plt.axis('off')\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "def caption_images(img_path):\r\n",
    "    print(f\"This looks like a: {predict_aircraft(img_path)}\")\r\n",
    "    plot_image(img_path)\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_test_img_dir = glob(\"../data/processed/test_images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in random.sample(list(extra_test_img_dir),3):\r\n",
    "    caption_images(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}